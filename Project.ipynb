{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center;\"> MACHINE LEARNING 1D PROJECT </h3>\n",
    "<h4 style=\"text-align:center;\"> Team Imagine Losing </h4>\n",
    "\n",
    "<h5><i> Group Members:</i> </h5>\n",
    "<ul>\n",
    "  <li>Ann Mary Alen 1005382</li>\n",
    "  <li>Emmanuel Lopez 1005400</li>\n",
    "  <li>Fu Meihui 1004864</li>\n",
    "  <li>Keshav Natarajan 1005495</li>\n",
    "  <li>Xu Muzi 1005641</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>LOADING DATASETS</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17179</th>\n",
       "      <td>17180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17180</th>\n",
       "      <td>17181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>17182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17182</th>\n",
       "      <td>17183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17183</th>\n",
       "      <td>17184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17184 rows × 5002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label    0    1    2    3    4    5    6    7  ...  4990  4991  \\\n",
       "0          1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1          2      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2          3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3          4      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4          5      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "...      ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "17179  17180      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "17180  17181      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "17181  17182      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "17182  17183      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "17183  17184      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "       4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "17179   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17180   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17181   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17182   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17183   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[17184 rows x 5002 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Train Datasets\n",
    "df_train=pd.read_csv('csv/train_tfidf_features.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>21476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>21477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>21478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>21479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>21480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4296 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    0    1    2    3    4    5    6    7    8  ...  4990  4991  \\\n",
       "0     17185  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1     17186  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2     17187  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3     17188  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4     17189  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "4291  21476  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4292  21477  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4293  21478  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4294  21479  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4295  21480  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4291   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4292   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4293   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4294   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4295   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4296 rows x 5001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test Dataset\n",
    "df_test=pd.read_csv('csv/test_tfidf_features.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>DATA PREPROCESSING</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reformatting\n",
    "\n",
    "# Dropping columns 'id' and 'label' from dataframe df_train and assigning it to df_train_dropped\n",
    "df_train_dropped=df_train.drop(['id','label'], axis=1); \n",
    "# Extracting labels from dataframe df_train and setting it to df_y\n",
    "df_y=df_train['label']; \n",
    "# Dropping column 'id'from df_test dataframe\n",
    "df_test_dropped = df_test.drop(['id'], axis=1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X,X_ and y to numpy arrays\n",
    "X = df_train_dropped.to_numpy()\n",
    "y = df_y.to_numpy()\n",
    "X_ = df_test_dropped.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17184 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "17179   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "17180   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "17181   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "17182   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "17183   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "       4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "17179   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17180   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17181   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17182   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "17183   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[17184 rows x 5000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying dataframe X\n",
    "display(pd.DataFrame(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17179</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17180</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17181</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17182</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17183</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17184 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "...   ..\n",
       "17179  0\n",
       "17180  0\n",
       "17181  1\n",
       "17182  1\n",
       "17183  0\n",
       "\n",
       "[17184 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying dataframe y\n",
    "display(pd.DataFrame(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4296 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  4990  \\\n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "4291   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4292   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4293   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4294   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4295   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "      4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4291   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4292   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4293   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4294   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4295   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4296 rows x 5000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying dataframe X_\n",
    "display(pd.DataFrame(X_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TASK 1 </h3>\n",
    "\n",
    "<i><h7> Problem Statement </h7></i>\n",
    "<p> Online hate speech is a serious problem that undermines the cohesion of online social communities and potentially puts society's public safety at risk. Researchers have created numerous conventional machine learning and deep learning techniques to automatically detect hate speech on online social platforms in response to this growing problem.\n",
    "\n",
    "In essence, the detection of online hate speech can be described as a text classification task: \"Classify if the post is hateful or non-hateful given a social media post.In order to come up with the best machine learning model for hate speech classification performance, our group started off by implementing the most commonly used classification algorithm, Logistic Regression from scratch in Task 1.</p>\n",
    "\n",
    "<i><h7> Functions Involved: </h7></i>\n",
    "\n",
    "- **$sigmoid(z)$**: A function that takes in a real number input and returns an output value between 0 and 1.\n",
    "<br/><br/>\n",
    "- **$loss(y, \\hat y)$**: A loss function of real $y$ value and our predicted $\\hat y$ value for us to minimize in order to determine the optimal parameters.\n",
    "<br/><br/>\n",
    "- **$gradients(X, y, \\hat y)$**: The Gradient Descent Algorithm to update and find the optimal value of parameters. The function takes in training feature $X$, actual labels y and the predicted labels $\\hat y$, returning the partial derivative of the Loss function with respect to weights $(w)$ and bias $(b)$.\n",
    "<br/><br/>\n",
    "- **$train(X, y, bs, epochs, lr)$**: The training function that includes parameters initialization and training loop with mini-batch gradient descent.\n",
    "<br/><br/>\n",
    "- **$predict(X)$**: The prediction function where we apply our validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7> Sigmoid Function </h7></i>\n",
    "\n",
    "Use the sigmoid function to squish the inputs between 0 and 1\n",
    "\n",
    "$$ σ(z) =  \\frac {1} {1+{e}^{-z}} $$\n",
    "\n",
    "In Logistic Regression, since $ \\hat y = wx + b$, our hypothsis will become \n",
    "$$ \\hat y = \\frac {1} {1+{e}^{-(wx+b)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7> Loss Function </h7></i><br></br>\n",
    "The loss function computes the distance between the real value and our prediction and evaluates the performance of the model. <br/>\n",
    "In order to obtain the optimal parameters $w$ and $b$ for the best prediction, we have to minimize the loss function.\n",
    "The Loss function we use here is the Log Loss Function as shown below (L here refers to the cost for ith training set)\n",
    "$$ Loss(w,b) = \\frac {1}{m} \\sum_{i=1}^{m} L({\\hat y}^{(i)}, {y}^{(i)}) = -\\frac {1}{m} \\sum_{i=1}^{m} {y}^{(i)}log(\\hat{y}^{(i)})-(1-{y}^{(i)})log(1-\\hat{y}^{(i)}) $$\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def loss(y, y_hat):\n",
    "    loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Gradient Descent Algorithm</h7></i><br></br>\n",
    "Gradient Descent Algorothm is an iterative first-order optimization algorithm that we use to find the local optimal values for our parameters ($w$, $b$) in the loss function(lr refers to learning rate)\n",
    "$$w = w - lr \\cdot dw $$\n",
    "$$b = b - lr \\cdot db $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "    #dw: weight, bias: db\n",
    "    n = X.shape[0]\n",
    "    dw = (1/n) * np.dot(X.T, (y_hat-y))\n",
    "    db = (1/n) * np.sum((y_hat-y))\n",
    "    return dw, db\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Train Function</h7></i><br></br>\n",
    "The <i>train</i> function includes initializing the $w$ (weights) and $b$(bias) and the training loop with mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, bs, epochs, lr):\n",
    "    theta = np.zeros((X.shape[1],1),dtype=float)\n",
    "    theta_0 = 0\n",
    "    \n",
    "    losses = []\n",
    "    for _ in range(epochs):\n",
    "        for i in range(((X.shape[0]-1)//bs) + 1):\n",
    "            # Batching\n",
    "            X_batch = X[i*bs : i*bs + bs]\n",
    "            y_batch = y[i*bs : i*bs + bs].reshape((-1,1))\n",
    "            \n",
    "            # Prediction\n",
    "            y_hat_batch = sigmoid(np.dot(X_batch, theta) + theta_0).reshape((-1,1))\n",
    "            \n",
    "            # Gradients\n",
    "            delta_theta, delta_theta_0 = gradients(X_batch, y_batch, y_hat_batch)\n",
    "            \n",
    "            # Update\n",
    "            theta -= lr * delta_theta\n",
    "            theta_0 -= lr * delta_theta_0\n",
    "        \n",
    "        # Calculate loss for current epoch\n",
    "        losses.append(loss(y, sigmoid(np.dot(X, theta) + theta_0)))\n",
    "        \n",
    "    return theta, theta_0, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7> Predict Function</h7></i><br></br>\n",
    "We get the prediction values using this function to get prepared for the comparison in the next function accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta, theta_0):\n",
    "    y_hat = sigmoid(np.dot(X, theta) + theta_0)\n",
    "\n",
    "    return np.array([1 if h >= 0.5 else 0 for h in y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7> Accuracy </h7></i><br></br>\n",
    "We compare the $y$ values with our predicted $\\hat y$ values and check in how mamy examples did we get the correct output, returning the accuracy as the mearsurement of our model's perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    accuracy = np.sum(y == y_hat) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement all our functions written above on the training and testing dataset and return the ouput CSV file as well as our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=0\n",
    ")\n",
    "theta, theta_0, losses = train(X_train, y_train, 100, 1000, 0.01)\n",
    "\n",
    "y_hat = predict(X_, theta, theta_0)\n",
    "\n",
    "pd.DataFrame(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(y_hat).set_index(df_test[\"id\"])\n",
    "pd.DataFrame(np.append(theta, [[theta_0]], axis=0)).to_csv(\"predictors.csv\")\n",
    "out.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(y_test, predict(X_test, theta, theta_0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> TASK 2 </h4>\n",
    "\n",
    "Dimension reduction is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data.<br>\n",
    "\n",
    "<i><b><h7>Dimensionality Reduction with Neighborhood Components Analysis</h7></b></i><br></br>\n",
    "In this task, we applied PCA, a well-known unsupervised dimensionality reduction technique to represent our multivariate data table as a smaller set of variables in order to observe trends, jumps, clusters and outliers. By doing so, we were able to reduce our training data containing 5000 TD-IDF features to 2000, 1000, 500 and 100 components and then applied it to the sklearn KNN machine learning model to obtain meangingful results.<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7>DATA PREPROCESSING</h7>\n",
    "\n",
    "In addition to the data preprocessing we performed earlier, a few additional steps must be performed before implementing PCA to get the most optimum results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5000)\n",
      "(4296, 5000)\n",
      "(21480, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the same random feature set must apply to the train and test datasets after reduction by PCA, we must first concat the two to get any meaningful results.\n",
    "# Printing the shapes of dataframes df_train_dropped and df_test_column to know the total number of rows that we will have after combining the two.\n",
    "print(df_train_dropped.shape)\n",
    "print(df_test_dropped.shape)\n",
    "# Concating preprocessed dataframes df_train_dropped and df_test_dropped.\n",
    "df_X_PCA=pd.concat([df_train_dropped,df_test_dropped]);\n",
    "# Printing out the results to make sure we have a new shape of (21480, 5000).\n",
    "print(df_X_PCA.shape)\n",
    "\n",
    "# Transform X and y to numpy arrays.\n",
    "X_PCA=df_X_PCA.to_numpy()\n",
    "y_PCA=df_y.to_numpy()\n",
    "\n",
    "#  Since PCA performs best with a normalized feature set, we must first perform normalization to normalize our feature set.\n",
    "X_PCA = normalize(X_PCA,axis=1)\n",
    "X_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform PCA as follows:\n",
    "<ol type=\"1\">\n",
    "<li> Initialize the PCA class by passing the number of components to the constructor. </li>\n",
    "<li> Call the fit and then transform methods by passing the feature set to these methods. The transform method returns the specified number of principal components. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing dimensionality of our combined dataset from 5000 features to 500 features using PCA.\n",
    "pca = PCA(n_components=2000)\n",
    "X_embedded = pca.fit_transform(X_PCA)\n",
    "pd.DataFrame(X_embedded)\n",
    "\n",
    "# We now split our combined dataset back to the training and test datasets.\n",
    "X_embedded_train = X_embedded[:17184]\n",
    "X_embedded_test = X_embedded[17184:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>KNN Machine Learning Model</h7></b><br></br>\n",
    "\n",
    "We apply the KNN model as follows:\n",
    "<ol type=\"1\">\n",
    "<li> Split the dataset to the training and testing dataset. </li>\n",
    "<li> Initialise K to 2 neighbors. </li>\n",
    "<li> Fit the datapoints to the nearest classifier to train the model.</li>\n",
    "<li> Compute the accuracy of the test results. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5073323421714979\n",
      "0.5073324022346368\n"
     ]
    }
   ],
   "source": [
    "# Perform train_test_split on the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embedded_train, y_PCA, test_size=0.5, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "n_neighbours=2\n",
    "# Use the nearest neighbor classifier to evaluate the methods with k=2\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbours)\n",
    "# Fit the nearest neighbor classifier on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "y_preds=knn.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "\n",
    "output = pd.DataFrame(knn.predict(X_embedded_test)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"outputPCA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, by repeating the same process for n_components= 1000, 500 and 100, we get the below results\n",
    "\n",
    "<ul>\n",
    "<li> 100 components - 64%</li>\n",
    "<li> 500 components - 64% </li>\n",
    "<li> 1000 components - 60%</li>\n",
    "<li> 2000 components - 51%</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> TASK 3 </h4>\n",
    "\n",
    "<p> In addition to the Logistic Regression and KNN machine learning models that we implemented as part of Task 1 and Task 2, we also iterated through five other models, optimizing for hyperparameters along the way namely:</p>\n",
    "<ul>\n",
    "<li> SVM Classifier</li>\n",
    "<li> GradientBoosting Classifier</li>\n",
    "<li> XGBoost Classifier</li>\n",
    "<li> RandomForest Classifier</li>\n",
    "<li> ExtraTrees Classifier</li>\n",
    "</ul>\n",
    "\n",
    "All models were primarily evaluated on the Macro F1 score metric to determine which model performed best. Out of all the models evaluated with optimized hyperparameters, the Extra Trees classifier performed the best, with a F1_macro score of 72.020% followed by linear SVM with a F1_macro score of 70.284%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>1. Support Vector Machine Classifier</h7></b>\n",
    "\n",
    "<p> Although some intital considerations when made when deciding which models to consider as our baseline value, we finally ended up choosing SVM given its degree of simplicity and the fact that it performed best among all the classifiers on the dimensionally reduced data with zero hyperparameter tuning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000)\n",
    "X_embedded = pca.fit_transform(X_PCA)\n",
    "X_embedded_train = X_embedded[:17184]\n",
    "X_embedded_test = X_embedded[17184:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_embedded_train, y, test_size=0.5, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_embedded_train, y_PCA)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Manual Hyperparameter Tuning</h7></i>\n",
    "\n",
    "<p> Since our training and test datasets are quite imbalanced and highly sparse , with the majority of values being zero, we ran our SVM model again but with the class_weight parameter set to \"balanced\".<p>\n",
    "<p> Additionally we also explored the various different kernels available ('linear', 'rbf', 'poly', 'sigmoid') to find which one best suits our data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><i>SVC= class_weight: 'balanced', kernel: 'linear' </i></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced', kernel = 'linear')\n",
    "clf.fit(X_embedded_train, y_PCA)\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><i>SVC= class_weight: 'balanced', kernel: 'rbf' </i></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced', kernel = 'rbf')\n",
    "clf.fit(X_embedded_train, y_PCA)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><i>SVC= class_weight: 'balanced', kernel: 'poly' </i></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced', kernel = 'poly')\n",
    "clf.fit(X_embedded_train, y_PCA)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><i>SVC= class_weight: 'balanced', kernel: 'sigmoid' </i></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced', kernel = 'sigmoid')\n",
    "clf.fit(X_embedded_train, y_PCA)\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds, average='macro'))\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> By comparing the different kernels, we found that the linear kernel performed best followed by sigmoid whereas rbf and poly were highly prone to overfitting. We also performed manual hyperparameter testing for gamma and C values on a reduced sample size, and then applied the best performing hyperparamters onto the entire dataset. </p>\n",
    "\n",
    "<ul>\n",
    "<li><i> Linear SVC, gamma= 1.0, C=1.0, training data: 17184 rows </i><br>\n",
    "     f1_macro: 0.7230437903804737,accuracy:  0.7754888268156425</li>\n",
    "     <li><i> Linear SVC, gamma= 1.75, C=7.25, training data: 17184 rows </i><br>\n",
    "     f1_macro: 0.7230437903804737, accuracy: 0.7754888268156425</li>\n",
    "     <li><i> Linear SVC, gamma= 1.75, C=7.25, training data: 17184 rows </i><br>\n",
    "     f1_macro: 0.7347987439337711, accuracy: 0.7837523277467412</li>\n",
    "     <li><i> Linear SVC, gamma= 1.75, C=10, training data: 17184 rows </i><br>\n",
    "     f1_macro: 0.7361051578796972 , accuracy: 0.7850325884543762</li>\n",
    "     <li><i> Linear SVC, gamma= 1.75, C=15, training data: 17184 rows </i><br>\n",
    "     f1_macro: 0.7375604208131931  , accuracy: 0.785148975791434</li>\n",
    "</ul>\n",
    "\n",
    "<p> Although the last few combinations seem to have better values, we found out that they were prone to slight overfitting with the actual f1_macro scores being around 69%, and we ultimately got our best results for SVM with the following hyperparameters: (class_weight='balanced', kernel = 'linear', gamma=1.0, C=1.0) with an f1_macro score of 70.372%.</p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>MODEL: SVMClassifier Pipeline</h7></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, stratify=y, random_state=0\n",
    ")\n",
    "# model\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA(n_components=2000)\n",
    "svc = svm.SVC(class_weight='balanced', kernel='linear')\n",
    "\n",
    "model = Pipeline(steps=[ (\"pca\", pca), (\"scaler\", scaler), (\"svc\", svc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Hyperparameter Tuning with GridSearchCV</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters checked\n",
    "param_grid = {\n",
    "    \"svc__C\": [5,10,1],\n",
    "    \"svc__gamma\": [0.01,0.1,1,\"auto\",\"scale\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, param_grid, n_jobs=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Scoring</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(\"F1 Macro Score:\",f1_score(y_test, y_preds, average='macro'))\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7><i>Best Classifier</i></h7><br>\n",
    "<ul>\n",
    "<li>svc__C: 1</li>\n",
    "<li>svc__gamma: 'scale'</li>\n",
    "</ul>\n",
    "<h8>Which are the default values for svm.SVC from sklearn</h8>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Training best SVM model</h7><i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced', kernel='linear').fit(X_embedded_train,y_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Predictions</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(clf.predict(X_embedded_test)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"output_SVC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><p> Despite our initial success with manual hyperparameter testing for the SVM model, we noticed that this was not feasible for our other machine learning models that involved a variety of different hyperparameters to be considered. Hence, we made use of model selection packages such as GradientSearchCV and RandomizedSearchCV for our remaining four models and optimized them to get the best results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h7>DATA PREPROCESSING</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the feature data\n",
    "X = normalize(X,axis=1)\n",
    "X_ = normalize(X_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split data with PCA (dimensionality reduction) to reduce code running time for initial model performance selection\n",
    "\n",
    "pca = PCA(n_components = 2000)\n",
    "X_embedded = pca.fit_transform(X)\n",
    "X_embedded_test = pca.transform(X_)\n",
    "\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(\n",
    "    X_embedded, y, test_size=0.2, stratify=y, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split data for initial model performance selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>2. Gradient Boosting Classifier</h7></b><br></br>\n",
    "\n",
    "<b><h7>MODEL: GradientBoostingClassifier Pipeline</h7></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"gbc\", gbc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Hyperparameter Tuning with GridSearchCV</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters checked\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [100, 500, 1000, 2000],\n",
    "    \"gbc__n_estimators\": [50,100,200],\n",
    "    \"gbc__learning_rate\": [1,0.1,0.01],\n",
    "    \"gbc__max_depth\": [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, param_grid, n_jobs=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Scoring</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(\"F1 Macro Score:\",f1_score(y_test, y_preds, average='macro'))\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7><i>Best Classifier</i></h7><br>\n",
    "<ul>\n",
    "<li>gbc__learning_rate: 0.1</li>\n",
    "<li>gbc__max_depth: 3</li>\n",
    "<li>gbc__n_estimators: 200</li>\n",
    "<li>pca__n_components: 2000</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Training</h7><i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2000)\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "clf = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"gbc\", gbc)]).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Predictions</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(clf.predict(X_)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"output_GBC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>3. XGBoost Classifier</h7></b><br></br>\n",
    "<b><h7>MODEL: XGBoostClassifier</h7></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Scoring</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "print(\"F1 Macro Score:\",f1_score(y_test, y_preds, average='macro'))\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Training</h7><i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Predictions</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(clf.predict(X_)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"output_GBC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>4. RandomForest Classifier</h7></b><br></br>\n",
    "<b><h7>MODEL: RandomForestClassifier</h7></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Hyperparameter Tuning with RandomizedSearchCV</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters checked\n",
    "params_grid = {\n",
    "    'n_estimators':[100, 200, 300, 400],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(model, params_grid, cv=3, n_iter=50, n_jobs=2, scoring='f1_macro')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Scoring</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(\"F1 Macro Score:\",f1_score(y_test, y_preds, average='macro'))\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7><i>Best Classifier</i></h7><br>\n",
    "<ul>\n",
    "<li>n_estimators: 300</li>\n",
    "<li>min_samples_split: 10</li>\n",
    "<li>min_samples_leaf: 2</li>\n",
    "<li>max_features: 'sqrt'</li>\n",
    "<li>max_depth: None</li>\n",
    "<li>bootstrap: False</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Training</h7><i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt', \n",
    "    max_depth=None,\n",
    "    bootstrap=False,\n",
    "    n_jobs=3,\n",
    "    random_state=0\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Predictions</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(clf.predict(X_)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"output_RTC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h7>5. Extra Trees Classifier</h7></b><br></br>\n",
    "\n",
    "<b><h7>MODEL: ExtraTreesClassifier</h7></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(n_jobs=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Hyperparameter Tuning with RandomizedSearchCV</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters checked\n",
    "params_grid = {\n",
    "    'n_estimators':[100, 200, 300, 400, 500],\n",
    "    'criterion': ['gini', 'log_loss', 'entropy'],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['log2', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(model, params_grid, cv=3, n_iter=100, n_jobs=2, scoring='f1_macro')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Scoring</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "print(\"F1 Macro Score:\",f1_score(y_test, y_preds, average='macro'))\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7><i>Best Classifier</i></h7><br>\n",
    "<ul>\n",
    "<li>n_estimators: 500</li>\n",
    "<li>min_samples_split: 10</li>\n",
    "<li>min_samples_leaf: 1</li>\n",
    "<li>max_features: 'sqrt'</li>\n",
    "<li>criterion:'entropy'</li>\n",
    "<li>bootstrap: False</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Training</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(\n",
    "    n_estimators=500, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt', \n",
    "    criterion='entropy', \n",
    "    bootstrap=False,\n",
    "    n_jobs=3,\n",
    "    random_state=0\n",
    ").fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h7>Predictions</h7></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(clf.predict(X_)).set_index(df_test[\"id\"])\n",
    "output\n",
    "output.to_csv(\"output_ETC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MODEL EVALUATION</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "SV_clf = svm.SVC(class_weight='balanced', kernel='linear', verbose=True).fit(X_train_PCA,y_train_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3100           26.39m\n",
      "         2           1.2941           26.19m\n",
      "         3           1.2803           25.96m\n",
      "         4           1.2689           25.83m\n",
      "         5           1.2589           25.69m\n",
      "         6           1.2504           25.55m\n",
      "         7           1.2421           25.50m\n",
      "         8           1.2355           25.35m\n",
      "         9           1.2288           25.27m\n",
      "        10           1.2234           25.11m\n",
      "        20           1.1801           23.76m\n",
      "        30           1.1513           22.39m\n",
      "        40           1.1278           21.03m\n",
      "        50           1.1071           19.70m\n",
      "        60           1.0895           18.41m\n",
      "        70           1.0719           17.07m\n",
      "        80           1.0562           15.75m\n",
      "        90           1.0403           14.45m\n",
      "       100           1.0246           13.13m\n",
      "       200           0.8975            0.00s\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2000)\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=0, verbose=True)\n",
    "\n",
    "GB_clf = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"gbc\", gbc)]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_clf = xgb.XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt', \n",
    "    max_depth=None,\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 15.4min finished\n"
     ]
    }
   ],
   "source": [
    "ET_clf = ExtraTreesClassifier(\n",
    "    n_estimators=500, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt', \n",
    "    criterion='entropy', \n",
    "    bootstrap=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    verbose=True\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing F1 Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.6931268589555004\n",
      "GBC: 0.6335151893748876\n",
      "XGB: 0.6634373048950617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 300 out of 300 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC: 0.7052796020342775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETC: 0.7030649293959036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 500 out of 500 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC:\", f1_score(y_test_PCA, SV_clf.predict(X_test_PCA), average='macro'))\n",
    "print(\"GBC:\", f1_score(y_test, GB_clf.predict(X_test), average='macro'))\n",
    "print(\"XGB:\", f1_score(y_test, XGB_clf.predict(X_test), average='macro'))\n",
    "print(\"RFC:\", f1_score(y_test, RF_clf.predict(X_test), average='macro'))\n",
    "print(\"ETC:\", f1_score(y_test, ET_clf.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CONCLUSION</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Although the RandomForestClassifer seems like the better machine learning model based on the model evaluation above, we noticed that in practice, the ExtraTreesClassifier seemed to be doing better by a slight margin based on the actual f1_macro scores obtained.Hence, ultimately our best model utilizes the ExtraTreesClassifier.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f6829e325472c7dc43a04a1a2a89a926f1541ca339a90a4ccf18c20d76fe3b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
